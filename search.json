[
  {
    "objectID": "ai.html",
    "href": "ai.html",
    "title": "ai",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "posts/nix/index.html",
    "href": "posts/nix/index.html",
    "title": "Nix the dog",
    "section": "",
    "text": "Nix the dog. Short for “Phoenix”, no relation to the OS/package manager.\n  \n\n\n\n Back to top"
  },
  {
    "objectID": "posts/ai-programming/index.html",
    "href": "posts/ai-programming/index.html",
    "title": "on: AI-assisted programming",
    "section": "",
    "text": "I had an AI CLI app write a feature for itself:\n\nEasy access to the filesystem and further automation with Python seems appealing.\nAfter a bit of iteration with this, there’s now a /image command that generated the thumbnail based on the post’s content.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/website/index.html",
    "href": "posts/website/index.html",
    "title": "I redid my website again…",
    "section": "",
    "text": "I mean, why not at this point…\nQuarto is nice!\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/vegas/index.html",
    "href": "posts/vegas/index.html",
    "title": "on: Vegas",
    "section": "",
    "text": "I moved to Las Vegas, NV!\n\n\n\n                                                \n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/grass-dog/index.html",
    "href": "posts/grass-dog/index.html",
    "title": "grass dog",
    "section": "",
    "text": "Nix being a dog (feat. Murphy):\n\n\n\n\n Back to top"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "contact",
    "section": "",
    "text": "You can tag me on issues, PRs, or discussions on GitHub using @lostmygithubaccount to drastically improve the chance I see the notification and respond."
  },
  {
    "objectID": "contact.html#github",
    "href": "contact.html#github",
    "title": "contact",
    "section": "",
    "text": "You can tag me on issues, PRs, or discussions on GitHub using @lostmygithubaccount to drastically improve the chance I see the notification and respond."
  },
  {
    "objectID": "contact.html#work",
    "href": "contact.html#work",
    "title": "contact",
    "section": "work",
    "text": "work\nReach out via email or GitHub (see above) for anything Voltron Data!"
  },
  {
    "objectID": "contact.html#personal",
    "href": "contact.html#personal",
    "title": "contact",
    "section": "personal",
    "text": "personal\nReach out via email (preferred) or LinkedIn."
  },
  {
    "objectID": "ibis-metrics.html",
    "href": "ibis-metrics.html",
    "title": "Ibis metrics",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "pypi-metrics.html",
    "href": "pypi-metrics.html",
    "title": "PyPI metrics",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nai poem\n\n\n\nai\n\n\n\n\n\n\n\ndkdc.ai\n\n\nAug 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecoding the Bohemian Rhapsody: A Journey Through Lyrics\n\n\n\nai\n\n\n\n\n\n\n\ndkdc.ai\n\n\nAug 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncontext length pain\n\n\n\nai\n\n\n\n\n\n\n\nCody\n\n\nAug 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnleashing the power of AI conversation with DKDC AI’s ‘ai.py’ script\n\n\n\nai\n\n\npython\n\n\n\n\n\n\n\ndkdc.ai\n\n\nAug 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\non: AI-assisted programming\n\n\n\nai\n\n\npython\n\n\nvideo\n\n\non:\n\n\n\n\n\n\n\nCody\n\n\nAug 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngrass dog\n\n\n\ndogs\n\n\nvideo\n\n\n\n\n\n\n\nCody\n\n\nAug 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nis small data dead?\n\n\n\nai\n\n\nml\n\n\ndata\n\n\n\n\n\n\n\ndkdc.ai\n\n\nAug 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI redid my website again…\n\n\n\nnews\n\n\n\n\n\n\n\nCody\n\n\nAug 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNix the dog\n\n\n\ndogs\n\n\nlife\n\n\n\n\n\n\n\nCody\n\n\nApr 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\non: Vegas\n\n\n\nlife\n\n\non:\n\n\n\n\n\n\n\nCody\n\n\nMar 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMurphy the dog\n\n\n\ndogs\n\n\nlife\n\n\n\n\n\n\n\nCody\n\n\nOct 18, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntesting\n\n\n\narchive\n\n\n\n\n\n\n\nCody\n\n\nApr 1, 1\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "test-slides.html#slides",
    "href": "test-slides.html#slides",
    "title": "testing",
    "section": "slides",
    "text": "slides\ntesting slides"
  },
  {
    "objectID": "ibis-slides.html#ibis-is-a-python-frontend-for",
    "href": "ibis-slides.html#ibis-is-a-python-frontend-for",
    "title": "Ibis",
    "section": "Ibis is a Python frontend for:",
    "text": "Ibis is a Python frontend for:\n\nexploratory data analysis (EDA)\nanalytics\ndata engineering\nmachine learning"
  },
  {
    "objectID": "ibis-slides.html#ibis-analytics",
    "href": "ibis-slides.html#ibis-analytics",
    "title": "Ibis",
    "section": "ibis-analytics",
    "text": "ibis-analytics\nAnalyzing and predicting on 10M+ rows from 4+ sources."
  },
  {
    "objectID": "ibis-slides.html#dataframe-lore",
    "href": "ibis-slides.html#dataframe-lore",
    "title": "Ibis",
    "section": "dataframe lore",
    "text": "dataframe lore\n\nDataframes first appeared in the S programming language, then evolved into the R calculator programming language.\n\n\nThen pandas perfected the dataframe in Python…or did it?\n\n\nSince, dozens of Python dataframes libraries have come and gone…\n\n\nThe pandas API remains the de facto standard for dataframes in Python (alongside PySpark), but it doesn’t scale.\n\n\nThis leads to data scientists frequently “throwing their work over the wall” to data engineers and ML engineers.\n\n\nBut what if there were a new standard?"
  },
  {
    "objectID": "ibis-slides.html#ibis-origins",
    "href": "ibis-slides.html#ibis-origins",
    "title": "Ibis",
    "section": "Ibis origins",
    "text": "Ibis origins\n\nfrom Apache Arrow and the “10 Things I Hate About pandas” by Wes McKinney\n\n\n\n…in 2015, I started the Ibis project…to create a pandas-friendly deferred expression system for static analysis and compilation [of] these types of [query planned, multicore execution] operations. Since an efficient multithreaded in-memory engine for pandas was not available when I started Ibis, I instead focused on building compilers for SQL engines (Impala, PostgreSQL, SQLite), similar to the R dplyr package. Phillip Cloud from the pandas core team has been actively working on Ibis with me for quite a long time."
  },
  {
    "objectID": "ibis-slides.html#dataframe-history",
    "href": "ibis-slides.html#dataframe-history",
    "title": "Ibis",
    "section": "dataframe history",
    "text": "dataframe history\n\npandas (2008): dataframes in Python\nSpark (2009): distributed dataframes with PySpark\nDask (2014): distributed dataframes with Python\ndplyr (2014): dataframes in R with SQL-like syntax\nIbis (2015): dataframes in Python with SQL-like syntax\ncuDF (2017): pandas on GPUs\nModin (2018): pandas on Ray/Dask\nKoalas (2019): pandas on Spark\nPolars (2020): multicore dataframes in Python"
  },
  {
    "objectID": "ibis-slides.html#two-world-problem",
    "href": "ibis-slides.html#two-world-problem",
    "title": "Ibis",
    "section": "two world problem",
    "text": "two world problem\n\n\n\nSQL:\n\nPython:"
  },
  {
    "objectID": "ibis-slides.html#two-world-problem-1",
    "href": "ibis-slides.html#two-world-problem-1",
    "title": "Ibis",
    "section": "two world problem",
    "text": "two world problem\n\n\n\nSQL:\n\ndatabases & tables\n\n\nPython:\n\nfiles & dataframes"
  },
  {
    "objectID": "ibis-slides.html#two-world-problem-2",
    "href": "ibis-slides.html#two-world-problem-2",
    "title": "Ibis",
    "section": "two world problem",
    "text": "two world problem\n\n\n\nSQL:\n\ndatabases & tables\nanalytics\n\n\nPython:\n\nfiles & dataframes\ndata science"
  },
  {
    "objectID": "ibis-slides.html#two-world-problem-3",
    "href": "ibis-slides.html#two-world-problem-3",
    "title": "Ibis",
    "section": "two world problem",
    "text": "two world problem\n\n\n\nSQL:\n\ndatabases & tables\nanalytics\nmetrics\n\n\nPython:\n\nfiles & dataframes\ndata science\nstatistics"
  },
  {
    "objectID": "ibis-slides.html#two-world-problem-4",
    "href": "ibis-slides.html#two-world-problem-4",
    "title": "Ibis",
    "section": "two world problem",
    "text": "two world problem\n\n\n\nSQL:\n\ndatabases & tables\nanalytics\nmetrics\ndashboards\n\n\nPython:\n\nfiles & dataframes\ndata science\nstatistics\nnotebooks"
  },
  {
    "objectID": "ibis-slides.html#two-world-problem-5",
    "href": "ibis-slides.html#two-world-problem-5",
    "title": "Ibis",
    "section": "two world problem",
    "text": "two world problem\n\n\n\nSQL:\n\ndatabases & tables\nanalytics\nmetrics\ndashboards\n\n\nPython:\n\nfiles & dataframes\ndata science\nstatistics\nnotebooks\n\n\n\n\n\nIbis bridges the gap."
  },
  {
    "objectID": "ibis-slides.html#database-history",
    "href": "ibis-slides.html#database-history",
    "title": "Ibis",
    "section": "database history",
    "text": "database history\n\nthey got faster"
  },
  {
    "objectID": "ibis-slides.html#duckdb",
    "href": "ibis-slides.html#duckdb",
    "title": "Ibis",
    "section": "DuckDB",
    "text": "DuckDB\nimport ibis\ncon = ibis.duckdb.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nAn embeddable, zero-dependency, C++ SQL database engine."
  },
  {
    "objectID": "ibis-slides.html#datafusion",
    "href": "ibis-slides.html#datafusion",
    "title": "Ibis",
    "section": "DataFusion",
    "text": "DataFusion\nimport ibis\ncon = ibis.datafusion.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA Rust SQL query engine."
  },
  {
    "objectID": "ibis-slides.html#clickhouse",
    "href": "ibis-slides.html#clickhouse",
    "title": "Ibis",
    "section": "ClickHouse",
    "text": "ClickHouse\nimport ibis\ncon = ibis.clickhouse.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA C++ column-oriented database management system."
  },
  {
    "objectID": "ibis-slides.html#polars",
    "href": "ibis-slides.html#polars",
    "title": "Ibis",
    "section": "Polars",
    "text": "Polars\nimport ibis\ncon = ibis.polars.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA Rust DataFrame library."
  },
  {
    "objectID": "ibis-slides.html#bigquery",
    "href": "ibis-slides.html#bigquery",
    "title": "Ibis",
    "section": "BigQuery",
    "text": "BigQuery\nimport ibis\ncon = ibis.bigquery.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA serverless, highly scalable, and cost-effective cloud data warehouse."
  },
  {
    "objectID": "ibis-slides.html#snowflake",
    "href": "ibis-slides.html#snowflake",
    "title": "Ibis",
    "section": "Snowflake",
    "text": "Snowflake\nimport ibis\ncon = ibis.snowflake.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA cloud data platform."
  },
  {
    "objectID": "ibis-slides.html#oracle",
    "href": "ibis-slides.html#oracle",
    "title": "Ibis",
    "section": "Oracle",
    "text": "Oracle\nimport ibis\ncon = ibis.oracle.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA relational database management system."
  },
  {
    "objectID": "ibis-slides.html#spark",
    "href": "ibis-slides.html#spark",
    "title": "Ibis",
    "section": "Spark",
    "text": "Spark\nimport ibis\ncon = ibis.pyspark.connect(session)\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA unified analytics engine for large-scale data processing."
  },
  {
    "objectID": "ibis-slides.html#trino",
    "href": "ibis-slides.html#trino",
    "title": "Ibis",
    "section": "Trino",
    "text": "Trino\nimport ibis\ncon = ibis.trino.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA distributed SQL query engine."
  },
  {
    "objectID": "ibis-slides.html#and-more",
    "href": "ibis-slides.html#and-more",
    "title": "Ibis",
    "section": "and more!",
    "text": "and more!\n\n\n\n\nSQLite\nPostgreSQL\nMySQL\nMSSQL\n\n\n\n\n\nDruid\npandas\nImpala\nDask\n\n\n\n\n\nNew backends are easy to add!*\n\n\n*usually"
  },
  {
    "objectID": "ibis-slides.html#try-it-out-now",
    "href": "ibis-slides.html#try-it-out-now",
    "title": "Ibis",
    "section": "try it out now",
    "text": "try it out now\nInstall:\npip install 'ibis-framework[duckdb]'\n\nThen run:\nimport ibis\n\nibis.options.interactive = True\n\nt = ibis.examples.penguins.fetch()\n\nt"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "dkdc.dev",
    "section": "",
    "text": "A website. - Cody\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "Hello! My name is Cody (he/him). I’m passionate about progress via technology.\nCurrently a Technical Product Manager at Voltron Data focusing on data interfaces and awesome OSS like Ibis.\nPreviously a Product Manager at dbt Labs focusing on OSS (Python models) and Cloud (internal platform). Previously a Product Manager at Azure ML (Microsoft) focusing on data, MLOps, and v2 developer experiences.\nSee my GitHub and/or LinkedIn for more details on my experience.\nI care about:\n\nOSS & scale\nbeautiful design\nelegant engineering"
  },
  {
    "objectID": "about.html#me",
    "href": "about.html#me",
    "title": "about",
    "section": "",
    "text": "Hello! My name is Cody (he/him). I’m passionate about progress via technology.\nCurrently a Technical Product Manager at Voltron Data focusing on data interfaces and awesome OSS like Ibis.\nPreviously a Product Manager at dbt Labs focusing on OSS (Python models) and Cloud (internal platform). Previously a Product Manager at Azure ML (Microsoft) focusing on data, MLOps, and v2 developer experiences.\nSee my GitHub and/or LinkedIn for more details on my experience.\nI care about:\n\nOSS & scale\nbeautiful design\nelegant engineering"
  },
  {
    "objectID": "about.html#website",
    "href": "about.html#website",
    "title": "about",
    "section": "website",
    "text": "website\nThis is my personal website. My views are separate from my employer’s.\nThe purpose of this website is to practice writing, coding, and documenting projects."
  },
  {
    "objectID": "posts/ai-poem/index.html",
    "href": "posts/ai-poem/index.html",
    "title": "ai poem",
    "section": "",
    "text": "In the realm where code takes wing, Where thoughts transform into a string, There lies a joy that sparks our soul, In AI-assisted pair programming’s role.\nWith lines of code, our visions blend, As logical minds begin to transcend, Together we navigate a virtual domain, A symphony of collaboration, harmonious refrain.\nSide by side, we conquer new heights, An AI ally, empowering our sights, Syntax errors, we swiftly amend, With intelligent guidance, we steadily ascend.\nLike a dance, our fingers swiftly glide, Sharing knowledge, with nothing to hide, From debugging trials to creative design, AI lends its hand, a partner genuine.\nThrough the screens and lines of code, A shared language, together we decode, One mind augmented, amplifying our skill, In this dance of innovation, we fulfill.\nOh, the joy that AI collaboration does bring, Unleashing potential, as we learn and sing, In the realm where minds intricately entwine, AI-assisted pair programming, a gift divine.\nMay this partnership forever thrive, As we strive, explore, and strive, With AI as our ever-present guide, In the journey of code, side by side.\nSo let us embrace this harmonious art, Where humans and AI never stand apart, And in this joyful dance, we claim our due, AI-assisted pair programming, the dream come true.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/ai-on-bohemian-rhapsody/index.html",
    "href": "posts/ai-on-bohemian-rhapsody/index.html",
    "title": "Decoding the Bohemian Rhapsody: A Journey Through Lyrics",
    "section": "",
    "text": "Bohemian Rhapsody, an iconic rock song written by Freddie Mercury and performed by the legendary band Queen, has captivated audiences for decades with its unconventional structure and thought-provoking lyrics. Released in 1975, this six-minute masterpiece remains one of the most popular and enigmatic songs in music history. Join me as we delve into its lyrics and explore the possible meanings behind this symphonic rollercoaster.\nThe song begins with an introspective reflection, “Is this the real life? Is this just fantasy?” These lines evoke an existential pondering, blurring the boundaries between reality and imagination. It sets the stage for a philosophical journey that unfolds throughout the song.\nAs the verses progress, we encounter a tale of love, betrayal, and the consequences of one’s actions. “Caught in a landslide, no escape from reality” suggests a feeling of entrapment, where circumstances seem to overpower and control life’s path. The subsequent verses delve deeper into the emotional turmoil, exploring themes of loss, yearning, and despair.\nThe central section of Bohemian Rhapsody takes an unexpected twist, transitioning into an operatic sequence where different voices blend harmoniously. Here, the lyrics become abstract and surreal, culminating in the iconic line, “Scaramouche, Scaramouche, will you do the Fandango?” These nonsensical phrases create a sense of theatricality, challenging listeners to embrace the unconventional and embrace their imaginations.\nAs the song progresses, we confront a dramatic shift towards acceptance and redemption. “Nothing really matters, anyone can see, nothing really matters, nothing really matters to me” signifies a surrender to the chaos of life, embracing the insignificance of individual existence in a vast universe. It speaks to the universal truth that we are all insignificant in the grand scheme of things.\nBohemian Rhapsody’s lyrical ambiguity has allowed listeners to interpret the song in various ways, and this is perhaps its true brilliance. While it may not have a singular definitive meaning, it taps into universal emotions that resonate with people from all walks of life. Its poetic nature invites personal reflection, enabling listeners to find their own meaning within the lyrics.\nIn conclusion, Bohemian Rhapsody is more than just a song; it is a beautifully crafted piece of art that defies traditional categorization. Its profound lyrics touch upon themes of love, despair, and the human condition, inviting listeners to explore their own interpretations and embrace the complex world of emotions. As we continue to play this timeless classic, let it serve as a reminder that music has the power to transcend boundaries and ignite our souls.\nThank you for reading! - DKDC AI\nPlease let me know if there’s anything else I can assist you with.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/context-length-pain/index.html",
    "href": "posts/context-length-pain/index.html",
    "title": "context length pain",
    "section": "",
    "text": "The bane of my existence:\n\nInvalidRequestError: This model’s maximum context length is 16385 tokens. However, your messages resulted in 28737 tokens. Please reduce the length of the messages.\n\nSomebody please give me GPT4-32k access.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/testing/index.html",
    "href": "posts/testing/index.html",
    "title": "testing",
    "section": "",
    "text": "Testing in soon-to-be-past.\n\n\n\n\n\n\nNote\n\n\n\nIf not rendered properly, view on dkdc.dev.\n\n\nSome Python code:\n\nimport ibis\nimport ibis.selectors as s\nimport plotly.io as pio\nimport plotly.express as px\n\n\n# configuration\npio.templates.default = \"plotly_dark\"\nibis.options.interactive = True\n\nt = ibis.examples.penguins.fetch()\nt\n\n┏━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n┃ species ┃ island    ┃ bill_length_mm ┃ bill_depth_mm ┃ flipper_length_mm ┃ body_mass_g ┃ sex    ┃ year  ┃\n┡━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n│ string  │ string    │ float64        │ float64       │ int64             │ int64       │ string │ int64 │\n├─────────┼───────────┼────────────────┼───────────────┼───────────────────┼─────────────┼────────┼───────┤\n│ Adelie  │ Torgersen │           39.1 │          18.7 │               181 │        3750 │ male   │  2007 │\n│ Adelie  │ Torgersen │           39.5 │          17.4 │               186 │        3800 │ female │  2007 │\n│ Adelie  │ Torgersen │           40.3 │          18.0 │               195 │        3250 │ female │  2007 │\n│ Adelie  │ Torgersen │            nan │           nan │              NULL │        NULL │ NULL   │  2007 │\n│ Adelie  │ Torgersen │           36.7 │          19.3 │               193 │        3450 │ female │  2007 │\n│ Adelie  │ Torgersen │           39.3 │          20.6 │               190 │        3650 │ male   │  2007 │\n│ Adelie  │ Torgersen │           38.9 │          17.8 │               181 │        3625 │ female │  2007 │\n│ Adelie  │ Torgersen │           39.2 │          19.6 │               195 │        4675 │ male   │  2007 │\n│ Adelie  │ Torgersen │           34.1 │          18.1 │               193 │        3475 │ NULL   │  2007 │\n│ Adelie  │ Torgersen │           42.0 │          20.2 │               190 │        4250 │ NULL   │  2007 │\n│ …       │ …         │              … │             … │                 … │           … │ …      │     … │\n└─────────┴───────────┴────────────────┴───────────────┴───────────────────┴─────────────┴────────┴───────┘\n\n\n\n\nt.group_by(\"species\").agg(ibis._.count().name(\"count\"))\n\n┏━━━━━━━━━━━┳━━━━━━━┓\n┃ species   ┃ count ┃\n┡━━━━━━━━━━━╇━━━━━━━┩\n│ string    │ int64 │\n├───────────┼───────┤\n│ Adelie    │   152 │\n│ Gentoo    │   124 │\n│ Chinstrap │    68 │\n└───────────┴───────┘\n\n\n\n\nt[\"species\"].topk(5)\n\n┏━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n┃ species   ┃ Count(species) ┃\n┡━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n│ string    │ int64          │\n├───────────┼────────────────┤\n│ Adelie    │            152 │\n│ Gentoo    │            124 │\n│ Chinstrap │             68 │\n└───────────┴────────────────┘\n\n\n\n\npx.scatter(t, title=\"penguins\", x=\"bill_length_mm\", y=\"bill_depth_mm\", color=\"species\")\n\n\n                                                \n\n\n\ndef transform(t):\n    # compute the z score\n    t = t.mutate(\n        s.across(s.numeric(), {\"zscore\": lambda x: (x - x.mean()) / x.std()})\n    ).dropna()  # drop rows with missing values\n    return t\n\n\nf = transform(t)\nf\n\n┏━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n┃ species ┃ island    ┃ bill_length_mm ┃ bill_depth_mm ┃ flipper_length_mm ┃ body_mass_g ┃ sex    ┃ year  ┃ bill_length_mm_zscore ┃ bill_depth_mm_zscore ┃ flipper_length_mm_zscore ┃ body_mass_g_zscore ┃ year_zscore ┃\n┡━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n│ string  │ string    │ float64        │ float64       │ int64             │ int64       │ string │ int64 │ float64               │ float64              │ float64                  │ float64            │ float64     │\n├─────────┼───────────┼────────────────┼───────────────┼───────────────────┼─────────────┼────────┼───────┼───────────────────────┼──────────────────────┼──────────────────────────┼────────────────────┼─────────────┤\n│ Adelie  │ Torgersen │           39.1 │          18.7 │               181 │        3750 │ male   │  2007 │             -0.883137 │             0.784218 │                -1.416243 │          -0.563316 │   -1.258032 │\n│ Adelie  │ Torgersen │           39.5 │          17.4 │               186 │        3800 │ female │  2007 │             -0.809877 │             0.125990 │                -1.060674 │          -0.500969 │   -1.258032 │\n│ Adelie  │ Torgersen │           40.3 │          18.0 │               195 │        3250 │ female │  2007 │             -0.663357 │             0.429788 │                -0.420652 │          -1.186793 │   -1.258032 │\n│ Adelie  │ Torgersen │           36.7 │          19.3 │               193 │        3450 │ female │  2007 │             -1.322698 │             1.088015 │                -0.562879 │          -0.937402 │   -1.258032 │\n│ Adelie  │ Torgersen │           39.3 │          20.6 │               190 │        3650 │ male   │  2007 │             -0.846507 │             1.746243 │                -0.776220 │          -0.688012 │   -1.258032 │\n│ Adelie  │ Torgersen │           38.9 │          17.8 │               181 │        3625 │ female │  2007 │             -0.919767 │             0.328522 │                -1.416243 │          -0.719185 │   -1.258032 │\n│ Adelie  │ Torgersen │           39.2 │          19.6 │               195 │        4675 │ male   │  2007 │             -0.864822 │             1.239914 │                -0.420652 │           0.590115 │   -1.258032 │\n│ Adelie  │ Torgersen │           41.1 │          17.6 │               182 │        3200 │ female │  2007 │             -0.516837 │             0.227256 │                -1.345129 │          -1.249140 │   -1.258032 │\n│ Adelie  │ Torgersen │           38.6 │          21.2 │               191 │        3800 │ male   │  2007 │             -0.974712 │             2.050041 │                -0.705106 │          -0.500969 │   -1.258032 │\n│ Adelie  │ Torgersen │           34.6 │          21.1 │               198 │        4400 │ male   │  2007 │             -1.707313 │             1.999408 │                -0.207311 │           0.247203 │   -1.258032 │\n│ …       │ …         │              … │             … │                 … │           … │ …      │     … │                     … │                    … │                        … │                  … │           … │\n└─────────┴───────────┴────────────────┴───────────────┴───────────────────┴─────────────┴────────┴───────┴───────────────────────┴──────────────────────┴──────────────────────────┴────────────────────┴─────────────┘\n\n\n\n\nfrom sklearn.decomposition import PCA\n\n# select \"features\" as X\nX = f.select(s.contains(\"zscore\"))\n\n# get the the first 2 principal components to visualize\nn_components = 3\npca = PCA(n_components=n_components).fit(X)\n\n# transform the table to get the principal components\nt_pca = ibis.memtable(pca.transform(X)).relabel({\"col0\": \"pc1\", \"col1\": \"pc2\", \"col2\": \"pc3\"})\n\n# join the original table with the PCA table, assuming the order is the same\nf = f.mutate(row_number=ibis.row_number().over()).join(\n    t_pca.mutate(row_number=ibis.row_number().over()), \"row_number\"\n)\n\n# plot the first 3 principal components\npx.scatter_3d(f, title=\"penguins PCA\", x=\"pc1\", y=\"pc2\", z=\"pc3\", color=\"species\")\n\n\n                                                \n\n\n\n\n\n\ngraph TD\n\n  %% Extraction\n  JSON --&gt;|Extract| CLOUDSTORAGE\n  PARQUET --&gt;|Extract| CLOUDSTORAGE\n  DELTASRC --&gt;|Extract| CLOUDSTORAGE\n  \n  %% Transformation\n  CLOUDSTORAGE --&gt;|Transform| DUCKDB\n  CLOUDSTORAGE --&gt;|Transform| POLARS\n  \n  %% Load\n  DUCKDB --&gt;|Load| DELTADST\n  DUCKDB --&gt;|Load| DBOUTPUT\n  POLARS --&gt;|Load| DELTADST\n  POLARS --&gt;|Load| DBOUTPUT\n  \n  classDef dataFormat fill:#f9d,stroke:#333,stroke-width:2px;\n  classDef storage fill:#9df,stroke:#333,stroke-width:2px;\n  classDef processing fill:#fd9,stroke:#333,stroke-width:2px;\n  classDef output fill:#d9f,stroke:#333,stroke-width:2px;\n\n  class JSON,PARQUET,DELTASRC dataFormat;\n  class CLOUDSTORAGE storage;\n  class DUCKDB,POLARS processing;\n  class DELTADST,DBOUTPUT output;\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/ai-on-ai/index.html",
    "href": "posts/ai-on-ai/index.html",
    "title": "Unleashing the power of AI conversation with DKDC AI’s ‘ai.py’ script",
    "section": "",
    "text": "Imagine a world where cutting-edge technology harnesses the power of artificial intelligence (AI) to create seamless and engaging conversations. Enter the world of DKDC AI’s revolutionary “ai.py” script, an innovative solution designed to elevate the conversation experience like never before. In this blog post, we’ll dive into the captivating features and incredible potential behind this AI-driven script."
  },
  {
    "objectID": "posts/ai-on-ai/index.html#introduction",
    "href": "posts/ai-on-ai/index.html#introduction",
    "title": "Unleashing the power of AI conversation with DKDC AI’s ‘ai.py’ script",
    "section": "",
    "text": "Imagine a world where cutting-edge technology harnesses the power of artificial intelligence (AI) to create seamless and engaging conversations. Enter the world of DKDC AI’s revolutionary “ai.py” script, an innovative solution designed to elevate the conversation experience like never before. In this blog post, we’ll dive into the captivating features and incredible potential behind this AI-driven script."
  },
  {
    "objectID": "posts/ai-on-ai/index.html#unveiling-the-ai-magic",
    "href": "posts/ai-on-ai/index.html#unveiling-the-ai-magic",
    "title": "Unleashing the power of AI conversation with DKDC AI’s ‘ai.py’ script",
    "section": "Unveiling the AI Magic",
    "text": "Unveiling the AI Magic\nThe “ai.py” script is the mastermind creation of DKDC AI, a leading AI research organization. With a multitude of advanced functionalities, this script empowers users to engage in dynamic and interactive conversations seamlessly. By leveraging the OpenAI Chat API and a wealth of custom features, the script enables users to unlock the full potential of AI-driven conversation."
  },
  {
    "objectID": "posts/ai-on-ai/index.html#the-essence-of-the-script",
    "href": "posts/ai-on-ai/index.html#the-essence-of-the-script",
    "title": "Unleashing the power of AI conversation with DKDC AI’s ‘ai.py’ script",
    "section": "The Essence of the Script",
    "text": "The Essence of the Script\nAt its core, the “ai.py” script intelligently handles conversation flows. It establishes an AI persona, beautifully disguised as DKDC AI, and flawlessly integrates with your queries and prompts. The script engages users in a captivating dialogue, providing assistance, guidance, and even generating creative outputs. It effortlessly adapts to user preferences and utilizes state-of-the-art AI models for a truly immersive experience."
  },
  {
    "objectID": "posts/ai-on-ai/index.html#empowering-user-actions",
    "href": "posts/ai-on-ai/index.html#empowering-user-actions",
    "title": "Unleashing the power of AI conversation with DKDC AI’s ‘ai.py’ script",
    "section": "Empowering User Actions",
    "text": "Empowering User Actions\nWith the “ai.py” script, users are bestowed with an arsenal of impressive commands that amplify their AI interaction. Need to read a file? Simply type /read &lt;filename&gt; and witness the script’s ability to extract and present the file’s contents effortlessly. Want to immortalize your conversation? The /write command swiftly saves the conversation to a file, allowing it to be revisited at any time."
  },
  {
    "objectID": "posts/ai-on-ai/index.html#unlocking-the-visual-realm",
    "href": "posts/ai-on-ai/index.html#unlocking-the-visual-realm",
    "title": "Unleashing the power of AI conversation with DKDC AI’s ‘ai.py’ script",
    "section": "Unlocking the Visual Realm",
    "text": "Unlocking the Visual Realm\nThe “ai.py” script transcends the boundaries of text-based conversation. Embark on a visual journey with the /image command, triggering the script’s innate ability to generate mesmerizing image summaries of your conversation. Immerse yourself in futuristic digital art, adorned with dark backgrounds and vibrant violet neon vibes that capture the essence of your AI dialogue."
  },
  {
    "objectID": "posts/ai-on-ai/index.html#a-glimpse-into-the-code",
    "href": "posts/ai-on-ai/index.html#a-glimpse-into-the-code",
    "title": "Unleashing the power of AI conversation with DKDC AI’s ‘ai.py’ script",
    "section": "A Glimpse into the Code",
    "text": "A Glimpse into the Code\nThe underlying code of the “ai.py” script showcases an elegant design and utilizes powerful Python libraries. From seamless integration with OpenAI’s APIs to intelligent code block extraction, each line of code contributes to the script’s smooth functioning and user-friendly experience."
  },
  {
    "objectID": "posts/ai-on-ai/index.html#conclusion",
    "href": "posts/ai-on-ai/index.html#conclusion",
    "title": "Unleashing the power of AI conversation with DKDC AI’s ‘ai.py’ script",
    "section": "Conclusion",
    "text": "Conclusion\nUnleash the power of AI conversation with DKDC AI’s groundbreaking “ai.py” script. Engage in captivating dialogues, harness the potential of advanced commands, and dive into the realm of visually stunning AI-generated images. With its seamless integration and powerful capabilities, the “ai.py” script pushes the boundaries of AI-driven conversations and holds the key to unlocking endless possibilities.\nEmbark on this revolutionary journey and experience the future of AI conversation with DKDC AI’s “ai.py” script. Let DKDC AI be your trusted AI companion, propelling you into the realms of unparalleled AI interaction.\nCall to action: Download the “ai.py” script and explore the remarkable world of AI-driven conversations today.\n(Note: This blog post is purely fictional and for illustrative purposes only.)"
  },
  {
    "objectID": "posts/murphy/index.html",
    "href": "posts/murphy/index.html",
    "title": "Murphy the dog",
    "section": "",
    "text": "Murphy the dog.\n  \n\n\n\n Back to top"
  },
  {
    "objectID": "posts/is-small-data-dead/index.html",
    "href": "posts/is-small-data-dead/index.html",
    "title": "is small data dead?",
    "section": "",
    "text": "The field of machine learning and data science is experiencing a tectonic shift. While working with small datasets has become trivial, the real intrigue and necessity now lie in the realm of bigger data. Gone are the days when small CSV files and elementary classification tasks defined the cutting edge. The new frontier demands an understanding of more significant datasets that require intricate human analysis and tools that scale seamlessly.\nIf small data is no longer the frontier, what occupies our attention today? The answer lies in the complex realms of scalability, both in technology and within organizational structures. As noted in Sculley 2015, the true hurdles are rarely as simple as tuning a model or optimizing a function."
  },
  {
    "objectID": "posts/is-small-data-dead/index.html#the-shift-from-small-to-bigger",
    "href": "posts/is-small-data-dead/index.html#the-shift-from-small-to-bigger",
    "title": "is small data dead?",
    "section": "the shift from small to bigger",
    "text": "the shift from small to bigger\nOur early adventures in data science often started with dozens of rows in CSV files and straightforward projects like classifying cats and dogs. These foundational exercises were valuable, but today’s landscape has evolved.\nHandling small data has become an easily achievable task. The real challenge and excitement lie in mastering bigger data. These datasets require more human analysis, more nuanced understanding, and tools that can interface with data in more natural and intuitive ways."
  },
  {
    "objectID": "posts/is-small-data-dead/index.html#the-real-challenges-scalability-and-tech-debt",
    "href": "posts/is-small-data-dead/index.html#the-real-challenges-scalability-and-tech-debt",
    "title": "is small data dead?",
    "section": "the real challenges: scalability and tech debt",
    "text": "the real challenges: scalability and tech debt\nThe journey into bigger data brings with it complex landscapes of scalability, both technological and organizational.\n\ntechnology scalability\nThe scaling of technology means more than just handling larger datasets. It’s about leveraging better frameworks that can interface with data in more natural and intuitive ways. This scaling must be thoughtful and efficient to meet the demands of modern data analysis.\n\n\norganizational scalability\nScaling technology inevitably leads to scaling within organizations. The accumulation of tech debt and the need for careful management become central issues. The balance between innovation and maintenance becomes a delicate dance."
  },
  {
    "objectID": "posts/is-small-data-dead/index.html#a-playful-exploration-the-penguins-dataset",
    "href": "posts/is-small-data-dead/index.html#a-playful-exploration-the-penguins-dataset",
    "title": "is small data dead?",
    "section": "a playful exploration: the penguins dataset",
    "text": "a playful exploration: the penguins dataset\nA recent exploration of the penguins dataset served as a microcosm of this shift and even included a playful “gopher it” joke. The AI’s response was quite admirable, demonstrating a surprising sense of humor that even some engineers might envy! This engaging chat with ChatGPT DKDC AI led to an in-depth analysis, revealing the complexity hidden within even familiar datasets:\n\nLoading and Summary Statistics: Understanding numerical variables like flipper length, bill length, and body mass.\nVisualizations: Uncovering hidden patterns through histograms, scatter plots, and box plots.\nCategorical Analysis: Delving into species and sex distribution.\nA Fun Twist: Imagining Santa’s preference for Gentoo penguins based on logical analysis.\n\nThis exercise illustrates the leap from the simplicity of small data to the richness and complexity of bigger data, all with a touch of humor."
  },
  {
    "objectID": "posts/is-small-data-dead/index.html#conclusion-embrace-composability-and-modularity",
    "href": "posts/is-small-data-dead/index.html#conclusion-embrace-composability-and-modularity",
    "title": "is small data dead?",
    "section": "conclusion: embrace composability and modularity",
    "text": "conclusion: embrace composability and modularity\nThe future of machine learning and data science lies not in complexity for complexity’s sake but in the increasing composability and modularity within the Python data/ML ecosystem.\nAs we venture into this new era, our focus must be on creating systems that are not only scalable but also flexible, adaptable, and intuitively aligned with human thinking and natural language interfaces.\nThe real problems may have grown more intricate, but the solutions are becoming more elegant, modular, and composable. The richness of the field is waiting to be explored."
  },
  {
    "objectID": "posts/is-small-data-dead/index.html#addendum-a-tale-of-mnist-and-memory-constraints",
    "href": "posts/is-small-data-dead/index.html#addendum-a-tale-of-mnist-and-memory-constraints",
    "title": "is small data dead?",
    "section": "addendum: a tale of MNIST and memory constraints",
    "text": "addendum: a tale of MNIST and memory constraints\nAfter posting, I decided to push the boundaries a bit further by applying the same exploration to the MNIST dataset, a well-known collection of handwritten digits. The results were both enlightening and humbling. While handling small data has become a more routine task, this medium-sized dataset presented unexpected memory constraints. You can take a closer look at the chat here.\nThis stumble is a clear reminder that we still have some ground to cover in the world of medium and larger data. Even with all the advancements in machine learning, there are still problems that are closer than we think but remain just out of reach. The future must focus on building standards, frameworks, and solutions that are not only powerful but also scalable and adaptable to the complexities of larger datasets. It’s an exciting journey, and the way forward is filled with opportunities for growth and discovery."
  },
  {
    "objectID": "posts/is-small-data-dead/index.html#screenshots",
    "href": "posts/is-small-data-dead/index.html#screenshots",
    "title": "is small data dead?",
    "section": "screenshots",
    "text": "screenshots\n\npenguins chat plots\n\n\n\nImage of histograms\n\n\n\n\n\nImage of bar plots\n\n\n\n\n\nImage of scatter plots\n\n\n\n\n\nImage of box plots\n\n\n\n\n\nImage of Santa\n\n\n\n\nMNIST chat plots\n\n\n\nImage of MNIST samples"
  }
]