[
  {
    "objectID": "ai.html",
    "href": "ai.html",
    "title": "ai",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "posts/nix/index.html",
    "href": "posts/nix/index.html",
    "title": "Nix the dog",
    "section": "",
    "text": "Nix the dog. Short for “Phoenix”, no relation to the OS/package manager.\n  \n\n\n\n Back to top"
  },
  {
    "objectID": "posts/website/index.html",
    "href": "posts/website/index.html",
    "title": "I redid my website again…",
    "section": "",
    "text": "I mean, why not at this point…\nQuarto is nice!\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/vegas/index.html",
    "href": "posts/vegas/index.html",
    "title": "on: Vegas",
    "section": "",
    "text": "I moved to Las Vegas, NV!\n\n\n\n                                                \n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about",
    "section": "",
    "text": "Hello! My name is Cody (he/him). I’m passionate about progress via technology.\nCurrently a Technical Product Manager at Voltron Data focusing on data interfaces and awesome OSS like Ibis.\nPreviously a Product Manager at dbt Labs focusing on OSS (Python models) and Cloud (internal platform). Previously a Product Manager at Azure ML (Microsoft) focusing on data, MLOps, and v2 developer experiences.\nSee my GitHub and/or LinkedIn for more details on my experience.\nI care about:\n\nOSS & scale\nbeautiful design\nelegant engineering"
  },
  {
    "objectID": "about.html#me",
    "href": "about.html#me",
    "title": "about",
    "section": "",
    "text": "Hello! My name is Cody (he/him). I’m passionate about progress via technology.\nCurrently a Technical Product Manager at Voltron Data focusing on data interfaces and awesome OSS like Ibis.\nPreviously a Product Manager at dbt Labs focusing on OSS (Python models) and Cloud (internal platform). Previously a Product Manager at Azure ML (Microsoft) focusing on data, MLOps, and v2 developer experiences.\nSee my GitHub and/or LinkedIn for more details on my experience.\nI care about:\n\nOSS & scale\nbeautiful design\nelegant engineering"
  },
  {
    "objectID": "about.html#website",
    "href": "about.html#website",
    "title": "about",
    "section": "website",
    "text": "website\nThis is my personal website. My views are separate from my employer’s.\nThe purpose of this website is to practice writing, coding, and documenting projects."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "dkdc.dev",
    "section": "",
    "text": "A website. - Cody\n\n\n Back to top"
  },
  {
    "objectID": "ibis-slides.html#ibis-is-a-python-frontend-for",
    "href": "ibis-slides.html#ibis-is-a-python-frontend-for",
    "title": "Ibis",
    "section": "Ibis is a Python frontend for:",
    "text": "Ibis is a Python frontend for:\n\nexploratory data analysis (EDA)\nanalytics\ndata engineering\nmachine learning"
  },
  {
    "objectID": "ibis-slides.html#ibis-analytics",
    "href": "ibis-slides.html#ibis-analytics",
    "title": "Ibis",
    "section": "ibis-analytics",
    "text": "ibis-analytics\nAnalyzing and predicting on 10M+ rows from 4+ sources."
  },
  {
    "objectID": "ibis-slides.html#dataframe-lore",
    "href": "ibis-slides.html#dataframe-lore",
    "title": "Ibis",
    "section": "dataframe lore",
    "text": "dataframe lore\n\nDataframes first appeared in the S programming language, then evolved into the R calculator programming language.\n\n\nThen pandas perfected the dataframe in Python…or did it?\n\n\nSince, dozens of Python dataframes libraries have come and gone…\n\n\nThe pandas API remains the de facto standard for dataframes in Python (alongside PySpark), but it doesn’t scale.\n\n\nThis leads to data scientists frequently “throwing their work over the wall” to data engineers and ML engineers.\n\n\nBut what if there were a new standard?"
  },
  {
    "objectID": "ibis-slides.html#ibis-origins",
    "href": "ibis-slides.html#ibis-origins",
    "title": "Ibis",
    "section": "Ibis origins",
    "text": "Ibis origins\n\nfrom Apache Arrow and the “10 Things I Hate About pandas” by Wes McKinney\n\n\n\n…in 2015, I started the Ibis project…to create a pandas-friendly deferred expression system for static analysis and compilation [of] these types of [query planned, multicore execution] operations. Since an efficient multithreaded in-memory engine for pandas was not available when I started Ibis, I instead focused on building compilers for SQL engines (Impala, PostgreSQL, SQLite), similar to the R dplyr package. Phillip Cloud from the pandas core team has been actively working on Ibis with me for quite a long time."
  },
  {
    "objectID": "ibis-slides.html#dataframe-history",
    "href": "ibis-slides.html#dataframe-history",
    "title": "Ibis",
    "section": "dataframe history",
    "text": "dataframe history\n\npandas (2008): dataframes in Python\nSpark (2009): distributed dataframes with PySpark\nDask (2014): distributed dataframes with Python\ndplyr (2014): dataframes in R with SQL-like syntax\nIbis (2015): dataframes in Python with SQL-like syntax\ncuDF (2017): pandas on GPUs\nModin (2018): pandas on Ray/Dask\nKoalas (2019): pandas on Spark\nPolars (2020): multicore dataframes in Python"
  },
  {
    "objectID": "ibis-slides.html#two-world-problem",
    "href": "ibis-slides.html#two-world-problem",
    "title": "Ibis",
    "section": "two world problem",
    "text": "two world problem\n\n\n\nSQL:\n\nPython:"
  },
  {
    "objectID": "ibis-slides.html#two-world-problem-1",
    "href": "ibis-slides.html#two-world-problem-1",
    "title": "Ibis",
    "section": "two world problem",
    "text": "two world problem\n\n\n\nSQL:\n\ndatabases & tables\n\n\nPython:\n\nfiles & dataframes"
  },
  {
    "objectID": "ibis-slides.html#two-world-problem-2",
    "href": "ibis-slides.html#two-world-problem-2",
    "title": "Ibis",
    "section": "two world problem",
    "text": "two world problem\n\n\n\nSQL:\n\ndatabases & tables\nanalytics\n\n\nPython:\n\nfiles & dataframes\ndata science"
  },
  {
    "objectID": "ibis-slides.html#two-world-problem-3",
    "href": "ibis-slides.html#two-world-problem-3",
    "title": "Ibis",
    "section": "two world problem",
    "text": "two world problem\n\n\n\nSQL:\n\ndatabases & tables\nanalytics\nmetrics\n\n\nPython:\n\nfiles & dataframes\ndata science\nstatistics"
  },
  {
    "objectID": "ibis-slides.html#two-world-problem-4",
    "href": "ibis-slides.html#two-world-problem-4",
    "title": "Ibis",
    "section": "two world problem",
    "text": "two world problem\n\n\n\nSQL:\n\ndatabases & tables\nanalytics\nmetrics\ndashboards\n\n\nPython:\n\nfiles & dataframes\ndata science\nstatistics\nnotebooks"
  },
  {
    "objectID": "ibis-slides.html#two-world-problem-5",
    "href": "ibis-slides.html#two-world-problem-5",
    "title": "Ibis",
    "section": "two world problem",
    "text": "two world problem\n\n\n\nSQL:\n\ndatabases & tables\nanalytics\nmetrics\ndashboards\n\n\nPython:\n\nfiles & dataframes\ndata science\nstatistics\nnotebooks\n\n\n\n\n\nIbis bridges the gap."
  },
  {
    "objectID": "ibis-slides.html#database-history",
    "href": "ibis-slides.html#database-history",
    "title": "Ibis",
    "section": "database history",
    "text": "database history\n\nthey got faster"
  },
  {
    "objectID": "ibis-slides.html#duckdb",
    "href": "ibis-slides.html#duckdb",
    "title": "Ibis",
    "section": "DuckDB",
    "text": "DuckDB\nimport ibis\ncon = ibis.duckdb.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nAn embeddable, zero-dependency, C++ SQL database engine."
  },
  {
    "objectID": "ibis-slides.html#datafusion",
    "href": "ibis-slides.html#datafusion",
    "title": "Ibis",
    "section": "DataFusion",
    "text": "DataFusion\nimport ibis\ncon = ibis.datafusion.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA Rust SQL query engine."
  },
  {
    "objectID": "ibis-slides.html#clickhouse",
    "href": "ibis-slides.html#clickhouse",
    "title": "Ibis",
    "section": "ClickHouse",
    "text": "ClickHouse\nimport ibis\ncon = ibis.clickhouse.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA C++ column-oriented database management system."
  },
  {
    "objectID": "ibis-slides.html#polars",
    "href": "ibis-slides.html#polars",
    "title": "Ibis",
    "section": "Polars",
    "text": "Polars\nimport ibis\ncon = ibis.polars.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA Rust DataFrame library."
  },
  {
    "objectID": "ibis-slides.html#bigquery",
    "href": "ibis-slides.html#bigquery",
    "title": "Ibis",
    "section": "BigQuery",
    "text": "BigQuery\nimport ibis\ncon = ibis.bigquery.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA serverless, highly scalable, and cost-effective cloud data warehouse."
  },
  {
    "objectID": "ibis-slides.html#snowflake",
    "href": "ibis-slides.html#snowflake",
    "title": "Ibis",
    "section": "Snowflake",
    "text": "Snowflake\nimport ibis\ncon = ibis.snowflake.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA cloud data platform."
  },
  {
    "objectID": "ibis-slides.html#oracle",
    "href": "ibis-slides.html#oracle",
    "title": "Ibis",
    "section": "Oracle",
    "text": "Oracle\nimport ibis\ncon = ibis.oracle.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA relational database management system."
  },
  {
    "objectID": "ibis-slides.html#spark",
    "href": "ibis-slides.html#spark",
    "title": "Ibis",
    "section": "Spark",
    "text": "Spark\nimport ibis\ncon = ibis.pyspark.connect(session)\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA unified analytics engine for large-scale data processing."
  },
  {
    "objectID": "ibis-slides.html#trino",
    "href": "ibis-slides.html#trino",
    "title": "Ibis",
    "section": "Trino",
    "text": "Trino\nimport ibis\ncon = ibis.trino.connect()\npenguins = con.table(\"penguins\")\npenguins.group_by([\"species\", \"island\"]).agg(ibis._.count().name(\"count\"))\nA distributed SQL query engine."
  },
  {
    "objectID": "ibis-slides.html#and-more",
    "href": "ibis-slides.html#and-more",
    "title": "Ibis",
    "section": "and more!",
    "text": "and more!\n\n\n\n\nSQLite\nPostgreSQL\nMySQL\nMSSQL\n\n\n\n\n\nDruid\npandas\nImpala\nDask\n\n\n\n\n\nNew backends are easy to add!*\n\n\n*usually"
  },
  {
    "objectID": "ibis-slides.html#try-it-out-now",
    "href": "ibis-slides.html#try-it-out-now",
    "title": "Ibis",
    "section": "try it out now",
    "text": "try it out now\nInstall:\npip install 'ibis-framework[duckdb]'\n\nThen run:\nimport ibis\n\nibis.options.interactive = True\n\nt = ibis.examples.penguins.fetch()\n\nt"
  },
  {
    "objectID": "test-slides.html#slides",
    "href": "test-slides.html#slides",
    "title": "testing",
    "section": "slides",
    "text": "slides\ntesting slides"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nis small data dead?\n\n\n\nai\n\n\nml\n\n\ndata\n\n\n\n\n\n\n\nCody + DKDC AI\n\n\nAug 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI redid my website again…\n\n\n\nnews\n\n\n\n\n\n\n\nCody\n\n\nAug 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNix the dog\n\n\n\ndogs\n\n\nlife\n\n\n\n\n\n\n\nCody\n\n\nApr 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\non: Vegas\n\n\n\nlife\n\n\non:\n\n\n\n\n\n\n\nCody\n\n\nMar 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMurphy the dog\n\n\n\ndogs\n\n\nlife\n\n\n\n\n\n\n\nCody\n\n\nOct 18, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntesting\n\n\n\narchive\n\n\n\n\n\n\n\nCody\n\n\nApr 1, 1\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "pypi-metrics.html",
    "href": "pypi-metrics.html",
    "title": "PyPI metrics",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "ibis-metrics.html",
    "href": "ibis-metrics.html",
    "title": "Ibis metrics",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "contact",
    "section": "",
    "text": "You can tag me on issues, PRs, or discussions on GitHub using @lostmygithubaccount to drastically improve the chance I see the notification and respond."
  },
  {
    "objectID": "contact.html#github",
    "href": "contact.html#github",
    "title": "contact",
    "section": "",
    "text": "You can tag me on issues, PRs, or discussions on GitHub using @lostmygithubaccount to drastically improve the chance I see the notification and respond."
  },
  {
    "objectID": "contact.html#work",
    "href": "contact.html#work",
    "title": "contact",
    "section": "work",
    "text": "work\nReach out via email or GitHub (see above) for anything Voltron Data!"
  },
  {
    "objectID": "contact.html#personal",
    "href": "contact.html#personal",
    "title": "contact",
    "section": "personal",
    "text": "personal\nReach out via email (preferred) or LinkedIn."
  },
  {
    "objectID": "posts/testing/index.html",
    "href": "posts/testing/index.html",
    "title": "testing",
    "section": "",
    "text": "Testing in soon-to-be-past.\n\n\n\n\n\n\nNote\n\n\n\nIf not rendered properly, view on dkdc.dev.\n\n\nSome Python code:\n\nimport ibis\nimport ibis.selectors as s\nimport plotly.io as pio\nimport plotly.express as px\n\n\n# configuration\npio.templates.default = \"plotly_dark\"\nibis.options.interactive = True\n\nt = ibis.examples.penguins.fetch()\nt\n\n┏━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n┃ species ┃ island    ┃ bill_length_mm ┃ bill_depth_mm ┃ flipper_length_mm ┃ body_mass_g ┃ sex    ┃ year  ┃\n┡━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n│ string  │ string    │ float64        │ float64       │ int64             │ int64       │ string │ int64 │\n├─────────┼───────────┼────────────────┼───────────────┼───────────────────┼─────────────┼────────┼───────┤\n│ Adelie  │ Torgersen │           39.1 │          18.7 │               181 │        3750 │ male   │  2007 │\n│ Adelie  │ Torgersen │           39.5 │          17.4 │               186 │        3800 │ female │  2007 │\n│ Adelie  │ Torgersen │           40.3 │          18.0 │               195 │        3250 │ female │  2007 │\n│ Adelie  │ Torgersen │            nan │           nan │              NULL │        NULL │ NULL   │  2007 │\n│ Adelie  │ Torgersen │           36.7 │          19.3 │               193 │        3450 │ female │  2007 │\n│ Adelie  │ Torgersen │           39.3 │          20.6 │               190 │        3650 │ male   │  2007 │\n│ Adelie  │ Torgersen │           38.9 │          17.8 │               181 │        3625 │ female │  2007 │\n│ Adelie  │ Torgersen │           39.2 │          19.6 │               195 │        4675 │ male   │  2007 │\n│ Adelie  │ Torgersen │           34.1 │          18.1 │               193 │        3475 │ NULL   │  2007 │\n│ Adelie  │ Torgersen │           42.0 │          20.2 │               190 │        4250 │ NULL   │  2007 │\n│ …       │ …         │              … │             … │                 … │           … │ …      │     … │\n└─────────┴───────────┴────────────────┴───────────────┴───────────────────┴─────────────┴────────┴───────┘\n\n\n\n\nt.group_by(\"species\").agg(ibis._.count().name(\"count\"))\n\n┏━━━━━━━━━━━┳━━━━━━━┓\n┃ species   ┃ count ┃\n┡━━━━━━━━━━━╇━━━━━━━┩\n│ string    │ int64 │\n├───────────┼───────┤\n│ Adelie    │   152 │\n│ Gentoo    │   124 │\n│ Chinstrap │    68 │\n└───────────┴───────┘\n\n\n\n\nt[\"species\"].topk(5)\n\n┏━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n┃ species   ┃ Count(species) ┃\n┡━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n│ string    │ int64          │\n├───────────┼────────────────┤\n│ Adelie    │            152 │\n│ Gentoo    │            124 │\n│ Chinstrap │             68 │\n└───────────┴────────────────┘\n\n\n\n\npx.scatter(t, title=\"penguins\", x=\"bill_length_mm\", y=\"bill_depth_mm\", color=\"species\")\n\n\n                                                \n\n\n\ndef transform(t):\n    # compute the z score\n    t = t.mutate(\n        s.across(s.numeric(), {\"zscore\": lambda x: (x - x.mean()) / x.std()})\n    ).dropna()  # drop rows with missing values\n    return t\n\n\nf = transform(t)\nf\n\n┏━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┓\n┃ species ┃ island    ┃ bill_length_mm ┃ bill_depth_mm ┃ flipper_length_mm ┃ body_mass_g ┃ sex    ┃ year  ┃ bill_length_mm_zscore ┃ bill_depth_mm_zscore ┃ flipper_length_mm_zscore ┃ body_mass_g_zscore ┃ year_zscore ┃\n┡━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━┩\n│ string  │ string    │ float64        │ float64       │ int64             │ int64       │ string │ int64 │ float64               │ float64              │ float64                  │ float64            │ float64     │\n├─────────┼───────────┼────────────────┼───────────────┼───────────────────┼─────────────┼────────┼───────┼───────────────────────┼──────────────────────┼──────────────────────────┼────────────────────┼─────────────┤\n│ Adelie  │ Torgersen │           39.1 │          18.7 │               181 │        3750 │ male   │  2007 │             -0.883137 │             0.784218 │                -1.416243 │          -0.563316 │   -1.258032 │\n│ Adelie  │ Torgersen │           39.5 │          17.4 │               186 │        3800 │ female │  2007 │             -0.809877 │             0.125990 │                -1.060674 │          -0.500969 │   -1.258032 │\n│ Adelie  │ Torgersen │           40.3 │          18.0 │               195 │        3250 │ female │  2007 │             -0.663357 │             0.429788 │                -0.420652 │          -1.186793 │   -1.258032 │\n│ Adelie  │ Torgersen │           36.7 │          19.3 │               193 │        3450 │ female │  2007 │             -1.322698 │             1.088015 │                -0.562879 │          -0.937402 │   -1.258032 │\n│ Adelie  │ Torgersen │           39.3 │          20.6 │               190 │        3650 │ male   │  2007 │             -0.846507 │             1.746243 │                -0.776220 │          -0.688012 │   -1.258032 │\n│ Adelie  │ Torgersen │           38.9 │          17.8 │               181 │        3625 │ female │  2007 │             -0.919767 │             0.328522 │                -1.416243 │          -0.719185 │   -1.258032 │\n│ Adelie  │ Torgersen │           39.2 │          19.6 │               195 │        4675 │ male   │  2007 │             -0.864822 │             1.239914 │                -0.420652 │           0.590115 │   -1.258032 │\n│ Adelie  │ Torgersen │           41.1 │          17.6 │               182 │        3200 │ female │  2007 │             -0.516837 │             0.227256 │                -1.345129 │          -1.249140 │   -1.258032 │\n│ Adelie  │ Torgersen │           38.6 │          21.2 │               191 │        3800 │ male   │  2007 │             -0.974712 │             2.050041 │                -0.705106 │          -0.500969 │   -1.258032 │\n│ Adelie  │ Torgersen │           34.6 │          21.1 │               198 │        4400 │ male   │  2007 │             -1.707313 │             1.999408 │                -0.207311 │           0.247203 │   -1.258032 │\n│ …       │ …         │              … │             … │                 … │           … │ …      │     … │                     … │                    … │                        … │                  … │           … │\n└─────────┴───────────┴────────────────┴───────────────┴───────────────────┴─────────────┴────────┴───────┴───────────────────────┴──────────────────────┴──────────────────────────┴────────────────────┴─────────────┘\n\n\n\n\nfrom sklearn.decomposition import PCA\n\n# select \"features\" as X\nX = f.select(s.contains(\"zscore\"))\n\n# get the the first 2 principal components to visualize\nn_components = 3\npca = PCA(n_components=n_components).fit(X)\n\n# transform the table to get the principal components\nt_pca = ibis.memtable(pca.transform(X)).relabel({\"col0\": \"pc1\", \"col1\": \"pc2\", \"col2\": \"pc3\"})\n\n# join the original table with the PCA table, assuming the order is the same\nf = f.mutate(row_number=ibis.row_number().over()).join(\n    t_pca.mutate(row_number=ibis.row_number().over()), \"row_number\"\n)\n\n# plot the first 3 principal components\npx.scatter_3d(f, title=\"penguins PCA\", x=\"pc1\", y=\"pc2\", z=\"pc3\", color=\"species\")\n\n\n                                                \n\n\n\n\n\n\ngraph TD\n\n  %% Extraction\n  JSON --&gt;|Extract| CLOUDSTORAGE\n  PARQUET --&gt;|Extract| CLOUDSTORAGE\n  DELTASRC --&gt;|Extract| CLOUDSTORAGE\n  \n  %% Transformation\n  CLOUDSTORAGE --&gt;|Transform| DUCKDB\n  CLOUDSTORAGE --&gt;|Transform| POLARS\n  \n  %% Load\n  DUCKDB --&gt;|Load| DELTADST\n  DUCKDB --&gt;|Load| DBOUTPUT\n  POLARS --&gt;|Load| DELTADST\n  POLARS --&gt;|Load| DBOUTPUT\n  \n  classDef dataFormat fill:#f9d,stroke:#333,stroke-width:2px;\n  classDef storage fill:#9df,stroke:#333,stroke-width:2px;\n  classDef processing fill:#fd9,stroke:#333,stroke-width:2px;\n  classDef output fill:#d9f,stroke:#333,stroke-width:2px;\n\n  class JSON,PARQUET,DELTASRC dataFormat;\n  class CLOUDSTORAGE storage;\n  class DUCKDB,POLARS processing;\n  class DELTADST,DBOUTPUT output;\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/murphy/index.html",
    "href": "posts/murphy/index.html",
    "title": "Murphy the dog",
    "section": "",
    "text": "Murphy the dog.\n  \n\n\n\n Back to top"
  },
  {
    "objectID": "posts/is-small-data-dead/index.html",
    "href": "posts/is-small-data-dead/index.html",
    "title": "is small data dead?",
    "section": "",
    "text": "The field of machine learning and data science is experiencing a tectonic shift. While working with small datasets has become trivial, the real intrigue and necessity now lie in the realm of bigger data. Gone are the days when small CSV files and elementary classification tasks defined the cutting edge. The new frontier demands an understanding of more significant datasets that require intricate human analysis and tools that scale seamlessly.\nIf small data is no longer the frontier, what occupies our attention today? The answer lies in the complex realms of scalability, both in technology and within organizational structures. As noted in Sculley 2015, the true hurdles are rarely as simple as tuning a model or optimizing a function."
  },
  {
    "objectID": "posts/is-small-data-dead/index.html#the-shift-from-small-to-bigger",
    "href": "posts/is-small-data-dead/index.html#the-shift-from-small-to-bigger",
    "title": "is small data dead?",
    "section": "the shift from small to bigger",
    "text": "the shift from small to bigger\nOur early adventures in data science often started with dozens of rows in CSV files and straightforward projects like classifying cats and dogs. These foundational exercises were valuable, but today’s landscape has evolved.\nHandling small data has become an easily achievable task. The real challenge and excitement lie in mastering bigger data. These datasets require more human analysis, more nuanced understanding, and tools that can interface with data in more natural and intuitive ways."
  },
  {
    "objectID": "posts/is-small-data-dead/index.html#the-real-challenges-scalability-and-tech-debt",
    "href": "posts/is-small-data-dead/index.html#the-real-challenges-scalability-and-tech-debt",
    "title": "is small data dead?",
    "section": "the real challenges: scalability and tech debt",
    "text": "the real challenges: scalability and tech debt\nThe journey into bigger data brings with it complex landscapes of scalability, both technological and organizational.\n\ntechnology scalability\nThe scaling of technology means more than just handling larger datasets. It’s about leveraging better frameworks that can interface with data in more natural and intuitive ways. This scaling must be thoughtful and efficient to meet the demands of modern data analysis.\n\n\norganizational scalability\nScaling technology inevitably leads to scaling within organizations. The accumulation of tech debt and the need for careful management become central issues. The balance between innovation and maintenance becomes a delicate dance."
  },
  {
    "objectID": "posts/is-small-data-dead/index.html#a-playful-exploration-the-penguins-dataset",
    "href": "posts/is-small-data-dead/index.html#a-playful-exploration-the-penguins-dataset",
    "title": "is small data dead?",
    "section": "a playful exploration: the penguins dataset",
    "text": "a playful exploration: the penguins dataset\nA recent exploration of the penguins dataset served as a microcosm of this shift and even included a playful “gopher it” joke. The AI’s response was quite admirable, demonstrating a surprising sense of humor that even some engineers might envy! This engaging chat with ChatGPT DKDC AI led to an in-depth analysis, revealing the complexity hidden within even familiar datasets:\n\nLoading and Summary Statistics: Understanding numerical variables like flipper length, bill length, and body mass.\nVisualizations: Uncovering hidden patterns through histograms, scatter plots, and box plots.\nCategorical Analysis: Delving into species and sex distribution.\nA Fun Twist: Imagining Santa’s preference for Gentoo penguins based on logical analysis.\n\nThis exercise illustrates the leap from the simplicity of small data to the richness and complexity of bigger data, all with a touch of humor."
  },
  {
    "objectID": "posts/is-small-data-dead/index.html#conclusion-embrace-composability-and-modularity",
    "href": "posts/is-small-data-dead/index.html#conclusion-embrace-composability-and-modularity",
    "title": "is small data dead?",
    "section": "conclusion: embrace composability and modularity",
    "text": "conclusion: embrace composability and modularity\nThe future of machine learning and data science lies not in complexity for complexity’s sake but in the increasing composability and modularity within the Python data/ML ecosystem.\nAs we venture into this new era, our focus must be on creating systems that are not only scalable but also flexible, adaptable, and intuitively aligned with human thinking and natural language interfaces.\nThe real problems may have grown more intricate, but the solutions are becoming more elegant, modular, and composable. The richness of the field is waiting to be explored."
  },
  {
    "objectID": "posts/is-small-data-dead/index.html#appendix",
    "href": "posts/is-small-data-dead/index.html#appendix",
    "title": "is small data dead?",
    "section": "appendix",
    "text": "appendix\n\npenguins chat plots\n\n\n\nImage of histograms\n\n\n\n\n\nImage of bar plots\n\n\n\n\n\nImage of scatter plots\n\n\n\n\n\nImage of box plots\n\n\n\n\n\nImage of Santa"
  }
]